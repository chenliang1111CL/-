## 使用方法：
* 我使用第一名参赛者的tools.py代码完成了样本集合的整理，形成了3倍上采样的影像和标签，并对他们进行了切片，形成512*512大小。代码使用比较简单，使用基线代码的docker镜像，参照第一名的说明，使用他的train.sh，把里边训练的命令删除，只执行到tool.py。
* 在数据整理后我们就不需要docker镜像了，直接用整理后的数据集开始后边的工作。
* 整理后的数据集结构：以我的电脑路径为例
```/home/user1/datasets/spacenet7/wdata
  ├── csvs: 训练和验证数据的路径集合，在完成上面的工作后，使用该项目中/test/makeCSV.py生成
  ├── train: 训练数据
  ├── test: 验证数据。由于原数据集test_public中未提供标签，我这里没有使用，而是从train中直接剪切出了一个地区作为验证数据
```
* 以train中某个区域的数据集合为例，展示数据集
```/home/user1/datasets/spacenet7/wdata/train/L15-0331E-1257N_1327_3160_13
  ├── images_masked_3x_divide: 上采样并分割好的影像
  ├── masks_3x_divide: 上采样并分割好的标签
  ├── 其它: 数据生成过程文件，训练部分暂不使用
```

## 训练方法
* 使用/HRNet_segmentation下的train.py进行训练，默认使用第二块GPU，数据路径如果和我一样就可以直接执行
* 本项目U-Net默认使用双线性插值做为上采样
* 本项目使用的HRNet网络，为了形成端到段的效果，修改了原网络最开始的两个下采样层，使输出与输入一致，也就是未进行任何下采样，直接开始并行阶段。同学也可以考虑使用原网络，先下采样两次再进入并行网络，然后在网络的输出部分实现两次上采样达到端对端的效果
* 默认是HRNet网络，切换网络只要在网络构建的地方注释掉HRNet，改为U-Net就行了

## 分割网络的实现不是本次实验的重点，同学们用本代码熟悉一下项目的工作流程就行了，重点还是放在分割后的数据后处理部分，充分发挥序列影像的特点，利用后处理实现房屋的追踪任务
